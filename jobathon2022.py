# -*- coding: utf-8 -*-
"""JobAThon2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KJke7doLbPXNv9gkSUMwjY28QR_5NnUd

##Importing libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import  mean_squared_error
import lightgbm as lgb

"""##Importing dataset"""

train = pd.read_csv('drive/MyDrive/Colab Notebooks/hackathon/train_E1GspfA.csv')
test = pd.read_csv('drive/MyDrive/Colab Notebooks/hackathon/test_6QvDdzb.csv')
submit = pd.read_csv('drive/MyDrive/Colab Notebooks/hackathon/sample_4E0BhPN.csv')

df = train.copy()

df.head()

"""##Feature Engineering"""

# Extract date feature
df['date'] = pd.to_datetime(df['date'])
df['year'] = df['date'].apply(lambda x: x.year)
df['month'] = df['date'].apply(lambda x: x.month)
df['day'] = df['date'].apply(lambda x: x.day)
df['day_of_week'] = df['date'].apply(lambda x: x.dayofweek)
df['is_quarter_date'] = df['date'].apply(lambda x: x.quarter)
df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x>4 else 0)

df.drop(['date'], axis=1, inplace=True)

df.head()

# Extract date feature for test
test['date'] = pd.to_datetime(test['date'])
test['year'] = test['date'].apply(lambda x: x.year)
test['month'] = test['date'].apply(lambda x: x.month)
test['day'] = test['date'].apply(lambda x: x.day)
test['day_of_week'] = test['date'].apply(lambda x: x.dayofweek)
test['is_quarter_date'] = test['date'].apply(lambda x: x.quarter)
test['is_weekend'] = test['day_of_week'].apply(lambda x: 1 if x>4 else 0)

test.drop(['date'], axis=1, inplace=True)

test.head()

plt.figure(figsize=(10,8))
sns.barplot(x=df['hour'], y=df['demand'])

# Checking the Correlation Between the Independent Variables

corr = df.corr()
mask = np.array(corr)
mask[np.tril_indices_from(mask)] = False
fig,ax= plt.subplots()
fig.set_size_inches(20,10)
sns.heatmap(corr, mask=mask,vmax=.8, square=True,annot=True)

"""##Modelling"""

#split df into X & y
y = df['demand'].copy()
X = df.drop('demand', axis=1).copy()

# Splitting data Into Training and Testing Set
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=41)

regressor = RandomForestRegressor(criterion='mse', random_state=123, max_depth=15, n_estimators=1000,min_samples_leaf=4, min_samples_split=2)

regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)

rmse = mean_squared_error(y_test, y_pred, squared=False)
rmse

gbm = lgb.LGBMRegressor(objective='regression', num_leaves=89,learning_rate=0.1,max_bin=200,min_sum_hessian_in_leaf = 20,
                        max_depth= 18,verbose=-1)

gbm.fit(x_train, y_train,eval_set=[(x_test, y_test)], eval_metric='l2_root', early_stopping_rounds=100)

y_pred = gbm.predict(x_test, num_iteration=gbm.best_iteration_)

rmse = mean_squared_error(y_test, y_pred, squared=False)
rmse

"""##Predicting"""

predict = gbm.predict(test)

rounded = [round(x) for x in predict]
predict = rounded

submit['demand'] = predict

submit.head()